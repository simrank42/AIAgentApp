# AI Chat Backend

A production-ready FastAPI backend with WebSocket support, JWT authentication, and multiple AI provider integrations.

## ğŸš€ Quick Links

- **[Deploy to Render](DEPLOY_TO_RENDER.md)** - Complete deployment guide
- **[Security Documentation](SECURITY.md)** - Security features and best practices

## âœ¨ Features

- **Authentication**: Email/password signup & login with Argon2 password hashing
- **JWT Tokens**: Access tokens (15min) + Refresh tokens (7 days) with HttpOnly cookies
- **WebSocket Streaming**: Real-time AI chat with token-by-token streaming
- **Multiple AI Providers**: 
  - Mock (testing)
  - Hugging Face (free tier)
  - OpenAI (optional)
- **Database Persistence**: SQLite with Litestream replication to Cloudflare R2
- **Row-level Security**: User-level data isolation enforced
- **Agent System**: Pre-configured AI agents (General, Coder, Security Analyst)
- **Production Ready**: Rate limiting, CORS, security headers, CSRF protection

## ğŸ› ï¸ Tech Stack

- Python 3.11+ Â· FastAPI Â· SQLAlchemy 2.x
- Alembic Â· Argon2 Â· JWT Â· WebSockets
- Litestream Â· Cloudflare R2
- Docker Â· Render

## ğŸ“¦ Installation

### Prerequisites
- Python 3.11+
- Docker (optional)

### Local Development

1. Clone and navigate to backend:
```bash
cd backend
```

2. Create virtual environment:
```bash
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -e .
```

4. Create `.env` file:
```bash
cp .env.example .env
# Edit .env with your configuration
```

5. Run database migrations:
```bash
alembic upgrade head
```

6. Start development server:
```bash
uvicorn app.main:app --reload --port 8000
```

Server runs at: http://localhost:8000

### Docker Development

```bash
cd backend
docker build -t chat-backend .
docker run -p 8000:8000 --env-file .env chat-backend
```

## ğŸŒ Production Deployment

See **[DEPLOY_TO_RENDER.md](DEPLOY_TO_RENDER.md)** for complete deployment instructions to Render with:
- Cloudflare R2 for database persistence
- Automatic backups
- Health checks
- Production security settings

## ğŸ“š API Documentation

Once running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

## ğŸ”§ Configuration

### Environment Variables

Key configuration options in `.env`:

```env
# Application
APP_ENV=dev  # or 'prod'
SECRET_KEY=your-secret-key-here
CORS_ORIGINS=http://localhost:4200

# Database
DATABASE_URL=sqlite:///./app.db

# AI Provider
AI_PROVIDER=huggingface  # or 'mock' or 'openai'
HF_TOKEN=your-huggingface-token
HF_MODEL=meta-llama/Llama-3.1-8B-Instruct

# Litestream (for production)
LITESTREAM_ACCESS_KEY_ID=your-r2-key
LITESTREAM_SECRET_ACCESS_KEY=your-r2-secret
LITESTREAM_BUCKET=your-bucket-name
LITESTREAM_ENDPOINT=https://your-account.r2.cloudflarestorage.com
```

See `.env.example` for all options.

## ğŸ—‚ï¸ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/          # API endpoints
â”‚   â”œâ”€â”€ core/            # Core configuration
â”‚   â”œâ”€â”€ db/              # Database & migrations
â”‚   â”œâ”€â”€ models/          # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/         # Pydantic schemas
â”‚   â”œâ”€â”€ services/        # Business logic
â”‚   â””â”€â”€ main.py          # Application entry point
â”œâ”€â”€ Dockerfile           # Container definition
â”œâ”€â”€ render.yaml          # Render deployment config
â”œâ”€â”€ litestream.yml       # Database replication config
â””â”€â”€ pyproject.toml       # Dependencies

```

## ğŸ§ª Testing

```bash
# Run tests
pytest

# Run with coverage
pytest --cov=app

# Check code quality
ruff check .
black --check .
```

## ğŸ“– License

MIT License - See LICENSE file for details

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“ Support

For issues, questions, or contributions, please open an issue on the repository.
